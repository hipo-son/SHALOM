"""VASP DFT backend implementation.

Handles full VASP input generation (POSCAR, INCAR, KPOINTS, POTCAR.spec)
with structure-aware auto-detection, and OUTCAR parsing with real force
extraction and optional pymatgen acceleration.
"""

from __future__ import annotations

import logging
import math
import os
import re
from typing import Any, Dict, List, Optional

from ase import Atoms
from ase.io import write

from shalom.backends._compression import compress_error_log, truncate_list
from shalom.backends.base import DFTResult
from shalom.backends.vasp_config import (
    VASPInputConfig,
    get_potcar_variant,
)

logger = logging.getLogger(__name__)

# Optional pymatgen — module-level import for thread safety.
try:
    from pymatgen.io.vasp.outputs import Vasprun, Outcar as PmgOutcar
    _PYMATGEN_AVAILABLE = True
except ImportError:
    _PYMATGEN_AVAILABLE = False


class VASPBackend:
    """VASP DFT backend implementation.

    Generates full VASP input sets (POSCAR + INCAR + KPOINTS + POTCAR.spec)
    when a ``VASPInputConfig`` is provided via the ``config`` keyword, and
    parses OUTCAR with real force/energy/entropy extraction.
    """

    name: str = "vasp"

    # ------------------------------------------------------------------
    # Input generation
    # ------------------------------------------------------------------

    def write_input(self, atoms: Atoms, directory: str, **params: Any) -> str:
        """Write VASP input files for the given structure.

        When ``config`` (VASPInputConfig) is passed in **params, generates all
        four input files. Otherwise falls back to POSCAR-only mode for backward
        compatibility.

        Args:
            atoms: ASE Atoms object representing the structure.
            directory: Target directory for the input files.
            **params: Optional parameters. Supported keys:
                - config (VASPInputConfig): Full input configuration.
                - filename (str): POSCAR filename. Defaults to "POSCAR".

        Returns:
            The directory path where input files were written.
        """
        os.makedirs(directory, exist_ok=True)
        config: Optional[VASPInputConfig] = params.pop("config", None)
        filename = params.get("filename", "POSCAR")

        # Always write POSCAR
        self._write_poscar(atoms, directory, filename)

        if config is not None:
            self._write_incar(atoms, directory, config)
            self._write_kpoints(atoms, directory, config)
            self._write_potcar_spec(atoms, directory, config)

        return directory

    def _write_poscar(self, atoms: Atoms, directory: str, filename: str = "POSCAR") -> str:
        filepath = os.path.join(directory, filename)
        write(filepath, atoms, format="vasp")
        return filepath

    def _write_incar(self, atoms: Atoms, directory: str, config: VASPInputConfig) -> str:  # noqa: ARG002
        """Generate INCAR from merged preset + user settings."""
        merged = config.get_merged_incar()

        # Apply GGA+U settings from ldau_settings if present
        if config.ldau_settings:
            for key in ("LDAU", "LDAUTYPE", "LDAUL", "LDAUU", "LDAUJ", "LDAUPRINT"):
                if key in config.ldau_settings and key not in config.user_incar_settings:
                    merged[key] = config.ldau_settings[key]

        filepath = os.path.join(directory, "INCAR")
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("# INCAR generated by SHALOM VASPBackend\n")
            for key, value in sorted(merged.items()):
                if isinstance(value, bool):
                    f.write(f" {key} = .{'TRUE' if value else 'FALSE'}.\n")
                elif isinstance(value, list):
                    f.write(f" {key} = {' '.join(str(v) for v in value)}\n")
                elif isinstance(value, float):
                    if abs(value) < 1e-3 and value != 0:
                        f.write(f" {key} = {value:.1E}\n")
                    else:
                        f.write(f" {key} = {value}\n")
                else:
                    f.write(f" {key} = {value}\n")
        return filepath

    def _write_kpoints(self, atoms: Atoms, directory: str, config: VASPInputConfig) -> str:  # noqa: ARG002
        """Generate KPOINTS file from config."""
        filepath = os.path.join(directory, "KPOINTS")
        kp = config.kpoints

        if kp.mode == "line":
            # Band structure line mode — placeholder
            with open(filepath, "w", encoding="utf-8") as f:
                f.write("K-Points along high symmetry lines\n")
                f.write(f"{kp.num_kpts_per_segment}\n")
                f.write("Line-mode\n")
                f.write("Reciprocal\n")
        elif kp.mode == "explicit" and kp.grid is not None:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write("Automatic mesh\n")
                f.write("0\n")
                f.write("Gamma\n")
                f.write(f" {kp.grid[0]}  {kp.grid[1]}  {kp.grid[2]}\n")
                f.write(" 0  0  0\n")
        else:
            # Automatic mode — use computed grid
            grid = kp.grid or [4, 4, 4]
            with open(filepath, "w", encoding="utf-8") as f:
                f.write("Automatic mesh\n")
                f.write("0\n")
                f.write("Gamma\n")
                f.write(f" {grid[0]}  {grid[1]}  {grid[2]}\n")
                f.write(" 0  0  0\n")
        return filepath

    def _write_potcar_spec(self, atoms: Atoms, directory: str, config: VASPInputConfig) -> str:
        """Write POTCAR.spec listing required pseudopotential variants.

        POTCAR files are under VASP license — we only generate the spec.
        """
        unique_elements = list(dict.fromkeys(atoms.get_chemical_symbols()))
        filepath = os.path.join(directory, "POTCAR.spec")
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("# POTCAR.spec - required pseudopotential variants\n")
            f.write(f"# Preset: {config.potcar_preset}\n")
            f.write(f"# Functional: {config.functional}\n")
            for el in unique_elements:
                variant = get_potcar_variant(el, config.potcar_preset)
                f.write(f"{variant}\n")
        return filepath

    # ------------------------------------------------------------------
    # Double relaxation
    # ------------------------------------------------------------------

    def write_double_relaxation(
        self, atoms: Atoms, base_dir: str, config: VASPInputConfig,
    ) -> List[str]:
        """Write two-step relaxation input sets.

        step1_coarse/: Loose convergence (EDIFFG=-0.05, NSW=50)
        step2_fine/:   Original config settings

        Args:
            atoms: ASE Atoms object.
            base_dir: Base directory.
            config: VASPInputConfig for the fine step.

        Returns:
            [step1_dir, step2_dir] paths.
        """
        from dataclasses import replace

        step1_dir = os.path.join(base_dir, "step1_coarse")
        step2_dir = os.path.join(base_dir, "step2_fine")

        # Step 1: coarse
        step1_incar = dict(config.incar_settings)
        step1_incar["EDIFFG"] = -0.05
        step1_incar["NSW"] = 50
        step1_config = replace(config, incar_settings=step1_incar, kpoints=replace(config.kpoints))
        self.write_input(atoms, step1_dir, config=step1_config)

        # Step 2: fine (original settings)
        self.write_input(atoms, step2_dir, config=config)

        return [step1_dir, step2_dir]

    @staticmethod
    def should_trigger_step2(
        initial_volume: float, final_volume: float, threshold: float = 0.03,
    ) -> bool:
        """Check if step2 should be triggered based on volume change.

        Only triggers step2 if volume change exceeds threshold (default 3%),
        avoiding unnecessary double relaxation.

        Args:
            initial_volume: Volume before relaxation (Angstrom^3).
            final_volume: Volume after step1 (Angstrom^3).
            threshold: Volume change ratio threshold.

        Returns:
            True if step2 is warranted.
        """
        if initial_volume <= 0:
            return False
        volume_change = abs(final_volume - initial_volume) / initial_volume
        return volume_change > threshold

    # ------------------------------------------------------------------
    # Output parsing
    # ------------------------------------------------------------------

    def parse_output(self, directory: str) -> DFTResult:
        """Parse VASP OUTCAR and return a unified DFTResult.

        Uses pymatgen if available for comprehensive parsing, otherwise
        falls back to regex-based OUTCAR parsing. Also performs smart context
        compression by extracting the tail of the OUTCAR if the run failed.

        Args:
            directory: Directory containing the OUTCAR file.

        Returns:
            DFTResult with energy, forces, convergence, entropy, and ionic history.

        Raises:
            FileNotFoundError: If no OUTCAR file is found in the directory.
        """
        outcar_path = os.path.join(directory, "OUTCAR")
        if not os.path.exists(outcar_path):
            raise FileNotFoundError(f"OUTCAR file not found: {outcar_path}")

        if _PYMATGEN_AVAILABLE:
            result = self._parse_with_pymatgen(directory)
        else:
            result = self._parse_regex(outcar_path)

        # Smart Context Compression: keyword-aware + tail truncation
        if not result.is_converged:
            try:
                with open(outcar_path, "r", encoding="utf-8") as f:
                    full_text = f.read()
                result.error_log = compress_error_log(full_text)
            except Exception:
                logger.debug("Error log extraction failed for %s", outcar_path)

        # Cap ionic history lists (prevent unbounded growth in long relaxations)
        result.ionic_energies = truncate_list(result.ionic_energies, 50)
        result.ionic_forces_max = truncate_list(result.ionic_forces_max, 50)

        return result

    def _parse_with_pymatgen(self, directory: str) -> DFTResult:
        """Parse using pymatgen Vasprun/Outcar for comprehensive data extraction."""
        outcar_path = os.path.join(directory, "OUTCAR")
        vasprun_path = os.path.join(directory, "vasprun.xml")

        outcar = PmgOutcar(outcar_path)

        energy = None
        bandgap = None
        magnetization = None
        is_converged = False
        forces_max = None

        # Try vasprun.xml first for richer data
        if os.path.exists(vasprun_path):
            try:
                vr = Vasprun(vasprun_path, parse_dos=False, parse_eigen=False)
                energy = vr.final_energy
                is_converged = vr.converged
                bandgap = vr.get_band_structure().get_band_gap().get("energy", None) if hasattr(vr, "get_band_structure") else None
            except Exception:
                pass

        # OUTCAR for forces and magnetization
        if energy is None and outcar.final_energy is not None:
            energy = outcar.final_energy
        if hasattr(outcar, "magnetization") and outcar.magnetization:
            try:
                magnetization = outcar.magnetization[-1].get("tot", {}).get("tot", None)
            except (IndexError, AttributeError, TypeError):
                pass

        # Convergence check from timing section if vasprun unavailable
        if not is_converged:
            with open(outcar_path, "r", encoding="utf-8") as f:
                text = f.read()
            if "General timing and accounting informations for this job" in text:
                is_converged = True

        raw = {"energy": energy, "is_converged": is_converged, "source": "pymatgen"}
        return DFTResult(
            energy=energy,
            forces_max=forces_max,
            is_converged=is_converged,
            bandgap=bandgap,
            magnetization=magnetization,
            raw=raw,
        )

    def _parse_regex(self, outcar_path: str) -> DFTResult:
        """Parse OUTCAR using regex patterns — pymatgen-free fallback."""
        with open(outcar_path, "r", encoding="utf-8") as f:
            text = f.read()

        energy = None
        is_converged = False
        forces_max = None
        all_forces: Optional[List[List[float]]] = None
        entropy_total = None
        num_atoms = None
        magnetization = None

        # Collect ionic step history
        ionic_energies: List[float] = []
        ionic_forces_max: List[float] = []

        lines = text.split("\n")
        i = 0
        while i < len(lines):
            line = lines[i]

            # Energy
            if "free  energy   TOTEN" in line:
                try:
                    e = float(line.split()[-2])
                    energy = e
                    ionic_energies.append(e)
                except (IndexError, ValueError):
                    pass

            # TOTAL-FORCE block
            if "TOTAL-FORCE (eV/Angst)" in line:
                # Skip the dashes line
                i += 1
                if i < len(lines) and "---" in lines[i]:
                    i += 1
                current_forces = []
                while i < len(lines) and "---" not in lines[i] and lines[i].strip():
                    parts = lines[i].split()
                    if len(parts) >= 6:
                        try:
                            fx, fy, fz = float(parts[3]), float(parts[4]), float(parts[5])
                            current_forces.append([fx, fy, fz])
                        except (IndexError, ValueError):
                            pass
                    i += 1
                if current_forces:
                    all_forces = current_forces
                    step_fmax = max(
                        math.sqrt(f[0]**2 + f[1]**2 + f[2]**2)
                        for f in current_forces
                    )
                    forces_max = step_fmax
                    ionic_forces_max.append(step_fmax)
                continue

            # Entropy T*S
            if "EENTRO" in line:
                match = re.search(r"EENTRO\s*=\s*([-\d.Ee+]+)", line)
                if match:
                    try:
                        entropy_total = float(match.group(1))
                    except ValueError:
                        pass

            # Number of atoms
            if "number of atoms/cell" in line:
                match = re.search(r"number of atoms/cell\s*=\s*(\d+)", line)
                if match:
                    num_atoms = int(match.group(1))

            # Magnetization
            if "number of electron" in line and "magnetization" in line:
                match = re.search(r"magnetization\s+([-\d.]+)", line)
                if match:
                    try:
                        magnetization = float(match.group(1))
                    except ValueError:
                        pass

            # Convergence (timing section present = job completed)
            if "General timing and accounting informations for this job" in line:
                is_converged = True

            i += 1

        # Compute entropy per atom
        entropy_per_atom = None
        if entropy_total is not None and num_atoms and num_atoms > 0:
            entropy_per_atom = entropy_total / num_atoms

        raw: Dict[str, Any] = {
            "energy": energy,
            "is_converged": is_converged,
            "forces_max": forces_max,
            "source": "regex",
        }

        return DFTResult(
            energy=energy,
            forces_max=forces_max,
            is_converged=is_converged,
            forces=all_forces,
            entropy_per_atom=entropy_per_atom,
            magnetization=magnetization,
            ionic_energies=ionic_energies if ionic_energies else None,
            ionic_forces_max=ionic_forces_max if ionic_forces_max else None,
            raw=raw,
        )
